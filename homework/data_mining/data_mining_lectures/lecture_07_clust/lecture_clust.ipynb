{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/header.png\"></center>\n",
    "\n",
    "<h1><center>Алгоритмы интеллектуальной обработки больших объемов данных</center></h1>\n",
    "<hr>\n",
    "<h2><center>Алгоритмы кластеризации</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "try:\n",
    "    from ipywidgets import interact, IntSlider, fixed, FloatSlider\n",
    "except ImportError:\n",
    "    print(u'Так надо')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Методы обучение без учителя (Unsupervised)\n",
    "\n",
    "* В чем отличие от Supervised методов?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Кластеризация\n",
    "* Уменьшение размерности\n",
    "    * Метод главных компонент\n",
    "    * Многомерное шкалирование\n",
    "    * Тематические модели*\n",
    "* Поиск ассоциативных правил"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Кластеризация\n",
    "\n",
    "Основная задача кластерного анализа — разбиение исходного набора объектов на группы (кластеры) таким образом, чтобы объекты в группе были похожи друг на друга, а объекты из разных групп - отличались.\n",
    "\n",
    "<center><img src=\"https://i.ytimg.com/vi/zPJtDohab-g/maxresdefault.jpg\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Группы методов\n",
    "\n",
    "* Методы основанные на прототипах\n",
    "* Иерархические методы\n",
    "* Плотностные методы\n",
    "* Спектральные методы\n",
    "* Сеточные методы\n",
    "* Вероятностные методы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Цели кластерного анализа\n",
    "\n",
    "* Поиск структуры в данных и ее интерпретация\n",
    "* Поиск аномальных объектов\n",
    "* Детальный анализ отдельных кластеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Алгоритм k-means\n",
    "\n",
    "* Дано множество объектов $X = \\{x_1, x_2, \\dots, x_N\\}$\n",
    "* Кластер $C_k \\Leftrightarrow \\text{ центройд } \\mu_k$\n",
    "* Объект $x_i \\in C_k \\Leftrightarrow \\mu_k = \\arg \\min\\limits_{\\mu_j} \\|x_i - \\mu_j \\|^2$\n",
    "* Надо найти такое разбиение на $K$ кластеров, чтобы минизировать\n",
    "$$ L(C) = \\sum_{k=1}^K\\sum_{i\\in C_k} ||x_i - \\mu_k||^2 \\rightarrow \\min\\limits_C $$\n",
    "$$\\mu_k = \\frac{1}{|C_k|} \\sum _{x_n \\in C_k} x_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Метод $k$-средних является итеративным алгоритмом разбиения множества объектов на $K$ кластеров "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Алгоритм k-means\n",
    "1. Выбрать $K$ начальных центроидов случайным образом  $\\rightarrow \\mu_k, \\ k=1\\dots K$\n",
    "2. Для каждой точки из датасета присвоить кластер, соответствующий ближайшему центроиду\n",
    "$$C_k = \\{x_n : ||x_n - \\mu_k||^2 \\leq ||x_n - \\mu_l||^2 \\quad \\forall l \\neq k \\} $$\n",
    "3. Обновить центройды: \n",
    "$$\\mu_k = \\frac{1}{|C_k|} \\sum _{x_n \\in C_k} x_n$$\n",
    "4. Повторять 2 и 3 до тех пор, пока изменения перестанут быть существенными \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/Kmeans_animation.gif' width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Основные факторы\n",
    "* Начальная инициализация центройдов\n",
    "* Количество кластеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Kак выбрать K?\n",
    "\n",
    "* Не пользоваться обычным k-means (X-means, ik-means)\n",
    "* Посмотреть на меры качества кластеризации\n",
    "* Воспользоваться эвристиками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Elbow method (Метод локтя)\n",
    "\n",
    "* Критерий минимизации k-means\n",
    "$$ L(C) = \\sum_{k=1}^K\\sum_{i\\in C_k} ||x_i - \\mu_k||^2 \\rightarrow \\min\\limits_C $$\n",
    "* Давайте возьмем всевозможные $K$, для каждого запустим алгоритм, посчитаем на результате $L(C)$ и выберем минимум!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Ничего не выйдет... Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     20,
     34,
     40
    ],
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X, y = make_blobs(n_samples=500,\n",
    "                  n_features=2,\n",
    "                  centers=4,\n",
    "                  cluster_std=1,\n",
    "                  center_box=(-10.0, 10.0),\n",
    "                  shuffle=True,\n",
    "                  random_state=1) \n",
    "\n",
    "\n",
    "crit = []\n",
    "\n",
    "for k in range(2, 8):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=1).fit(X)\n",
    "    crit.append(np.sqrt(kmeans.inertia_))\n",
    "    \n",
    "def elbow_demo(k=2):\n",
    "    \n",
    "    X, y = make_blobs(n_samples=500,\n",
    "                  n_features=2,\n",
    "                  centers=4,\n",
    "                  cluster_std=1,\n",
    "                  center_box=(-10.0, 10.0),\n",
    "                  shuffle=True,\n",
    "                  random_state=1) \n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k, random_state=1).fit(X)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    \n",
    "    ax[0].scatter(X[:,0], X[:,1], c=kmeans.labels_)\n",
    "    \n",
    "    ax[0].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
    "                  marker='o', c=\"white\", alpha=1, s=200)\n",
    "    \n",
    "    ax[0].set_xlabel('$x_1$')\n",
    "    ax[0].set_ylabel('$x_2$')\n",
    "\n",
    "    for i, c in enumerate(kmeans.cluster_centers_):\n",
    "        ax[0].scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50)\n",
    "        \n",
    "    ax[1].plot(range(2,8), crit, marker='s')\n",
    "    \n",
    "    ax[1].set_xlabel('$k$')\n",
    "    ax[1].set_ylabel('$L^{(k)}(C)$')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Elbow method (Метод локтя)\n",
    "\n",
    "* Выбирают такое $k$, после которого функционал $L(C)$ уменьшается не слишком быстро\n",
    "* Чуть более формально:\n",
    "$$ D(k) = \\frac{|L^{(k)}(C) - L^{(k+1)}(C)|}{|L^{(k-1)}(C) - L^{(k)}(C)|} \\quad \\text{\"невелико\"} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot = interact(elbow_demo, k=IntSlider(min=2,max=8,step=1,value=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Важно!\n",
    "* Эвристика и меры качества клатеризации носят лишь рекомендательный характер!\n",
    "* Если они ничего не дают, то лучше ориентироваться на свои знания в предметной области\n",
    "* Или \"выжать\" из полученной кластеризации максимум\n",
    "    * *3 из 5 полученных кластеров интерпретируются - и то хорошо*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Начальная инициализация центройдов\n",
    "* Выбрать координаты $K$ случайных объектов из датасета\n",
    "    * Производить случайные запуски много раз и выбрать наиболее оптимальную инициализацию\n",
    "* Использовать результат другой кластеризации на $K$ кластеров\n",
    "* k-means++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### K-means++\n",
    "* Первый центройд выбираем случайным образом из объектов датасета\n",
    "* Для каждой точки рассчитываем расстояние $d_{\\min}(x_i) = \\min_{\\mu_j} \\|x_i - \\mu_j\\|^2$\n",
    "* Точка назначается следующим центройдом с вероятностью $p(x_i) \\propto d_{\\min}(x_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def demo_kmpp(iters=1):\n",
    "\n",
    "    X, y = make_blobs(n_samples=550, cluster_std=1.5, n_features=2, centers=5, random_state=12345)\n",
    "\n",
    "    X_grid1, X_grid2 = np.meshgrid(np.linspace(-12, 18, 500),\n",
    "                                   np.linspace(-11, 8, 500))\n",
    "\n",
    "    XX = np.c_[X_grid1.flatten(), X_grid2.flatten()]\n",
    "    np.random.seed(1)\n",
    "    centroids = np.empty((0, 2))\n",
    "\n",
    "    for i in range(iters):\n",
    "        if i == 0:\n",
    "            d = np.ones_like(y, dtype=float)\n",
    "        else:\n",
    "            d = pairwise_distances(X, centroids, metric='euclidean').min(axis=1)\n",
    "        weights = d/d.sum()\n",
    "\n",
    "        centroid_idx = np.random.choice(X.shape[0], size=1, replace=False, p=weights)[0]\n",
    "        centroids = np.r_[centroids, X[centroid_idx, np.newaxis]]\n",
    "\n",
    "    d_grid = pairwise_distances(XX, centroids, metric='euclidean').min(axis=1)\n",
    "\n",
    "    d_grid = d_grid.reshape(X_grid1.shape)\n",
    "    d_grid = d_grid/d_grid.max()\n",
    "\n",
    "    levels = np.linspace(0, 1, 100)\n",
    "\n",
    "    plt.contourf(X_grid1, X_grid2, d_grid, cmap=plt.cm.Blues, alpha=0.7, levels=levels)\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=100)\n",
    "\n",
    "    centers = centroids\n",
    "    \n",
    "    plt.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=500, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        plt.scatter(c[0], c[1], marker='$%d$' % (i+1), alpha=1,\n",
    "                    s=100, edgecolor='k')\n",
    "\n",
    "    plt.xlabel('$x_1$', fontsize=15)\n",
    "    plt.ylabel('$x_2$', fontsize=15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "interact(demo_kmpp, iters=IntSlider(min=1,max=6,step=1,value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Резюме\n",
    "\n",
    "* Метод k-средних – жадный итеративный алгоритм\n",
    "* Зависит от начальных центройдов и их количества\n",
    "\n",
    "#### Преимущества\n",
    "* Прост как пробка\n",
    "* Имеет множество модификаций\n",
    "    * Разные меры близости ($k$-medians, $k$-medoids)\n",
    "    * Взвешивание признаков (Weighted $k$-means)\n",
    "    * Нечеткая принадлежность кластеров (fuzzy $c$-means)\n",
    "    * Для больших данных ([batch $k$-means](http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf))\n",
    "    * ...\n",
    "* Интерпретация кластеров через центройды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Недостатки\n",
    "* В результате получеются \"сферические\" кластеры что не всегда соответствует реальности.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Иерархическая кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Пример: семейства языков\n",
    "<center><img src='images/languages.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Пример: биология\n",
    "<center><img src='images/dinosaurs.jpg'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Аггломеративные алгоритмы **\n",
    "* начинаем с ситуации, когда каждый объект - отдельный кластер\n",
    "* на каждом шаге совмещаем два наиболее близких кластера\n",
    "* останавливаемся, когда получаем требуемое количество или единственный кластер\n",
    "\n",
    "\n",
    "** Дивизивные алгоритмы **\n",
    "* начинаем с ситуации, когда все объекты составляют один кластер\n",
    "* на каждом шаге разделяем один из кластеров пополам\n",
    "* останавливаемся, когда получаем требуемое количество или $N$ кластеров\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Аггломеративный алгоритм\n",
    "\n",
    "```{C}\n",
    "1. function agglomerative(X, K):\n",
    "\n",
    "2.\tinitialize N # number of objects\n",
    "3.\tinitialize C = N # number of clusters\n",
    "4.\tinitialize C_i = x_i # initial clusters\n",
    "5.\twhile C > K:\n",
    "6.\t\tC_a = C_b = None # closest clusters\n",
    "7.\t\tmin_dist = +inf # distance between closest\n",
    "8.\t\tfor i in 1 .. C:\n",
    "9.\t\t\tfor j in i + 1 .. C:\n",
    "10.\t\t\t\tdist = d(C_i, C_j) # dist. betw. clusters\n",
    "11.\t\t\t\tif dist < min_dist:\n",
    "12.\t\t\t\t\tmin_dist = dist\n",
    "13.\t\t\t\t\tC_a = C_i\n",
    "14.\t\t\t\t\tC_b = C_j\t\t\n",
    "15.\t\tmerge(C_a, C_b)\n",
    "\n",
    "16.\t\tC = C - 1\t\n",
    "17.\treturn C_1, ..., C_K\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/dendro1.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*  Как определять близкие объекты?\n",
    "*  Как пересчитывать расстояние между кластерами после объединения?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Меры близости\n",
    "\n",
    "* Как определить похожие объекты?\n",
    "\n",
    "* Необходимо ввести функцию расстояния (не обязательно метрику)\n",
    "\n",
    "### Количественные признаки\n",
    "\n",
    "$$ d(a, b) = \\sum\\limits_{i=1}^{D}(a_i - b_i)^2 \\text{: euclidean distance} $$\n",
    "\n",
    "$$ d(a, b) = \\sum\\limits_{i=1}^{D}|a_i - b_i| \\text{: manhattan distance} $$\n",
    "\n",
    "$$ d(a, b) = \\frac{\\langle a,b \\rangle}{||a||\\cdot||b||} \\text{: cosine similarity} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Близость на бинарных векторах\n",
    "\n",
    "* Пусть объект описываеться набором бинарных признаков <br/>(достиг 18 лет, отслужил в армии, закончил университет, женат)\n",
    "    * Иван: `(1, 0, 1, 0)`\n",
    "    * Геннадий:     `(1, 1, 0, 1)`\n",
    "* Расстояние Хэмминга -  Hamming distance\n",
    "    * Количество (доля) несовпавших значений\n",
    "    \n",
    "    $$d(\\text{Иван},\\text{Геннадий}) = 3 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Близость на множествах\n",
    "* Пусть объект описываеться набором категорий, слов, тегов\n",
    "    * Клиент a: {Картофель фри, биг-мак, кофе, маффин}\n",
    "    * Клиент b: {Картофель фри, сырный соус, чизбургер, кофе, пирожок}\n",
    "* Расстояние Жаккара - Jaccard distance:\n",
    "$$d(a,b) = 1 - \\frac{|a \\cap b|}{|a \\cup b|}$$\n",
    "\n",
    "$$d(a,b) = 1 - \\frac{2}{7} = \\frac{5}{7} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Расстояние на строках\n",
    "* Расстояние Левенштейна<br/>\n",
    "Количество вставок, замен и удалений, которое необходимо сделать, чтобы получить из строки $S_1$ строку $S_2$\n",
    "\n",
    "\\begin{equation}\n",
    " D ( i , j ) = \n",
    " \\begin{cases} \n",
    " {\\begin{array}{llcl}0,&&&i=0,\\ j=0\\\\i,&&&j=0,\\ i>0\\\\j,&&&i=0,\\ j>0\\\\\\min\\{\\\\&D(i,j-1)+1,\\\\&D(i-1,j)+1,&&j>0,\\ i>0\\\\&D(i-1,j-1)+{\\rm {m}}(S_{1}[i],S_{2}[j])\\\\\\}\\end{array}},\n",
    " \\end{cases} \n",
    "\\end{equation}\n",
    "где $m(a,b)$ - равно $0$, если $a = b$ и $1$ в ином случае\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/levinstein_dist.png' width=300></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Пересчет расстояний после объединения кластеров\n",
    "\n",
    "* Single linkage\n",
    "$$ d_{min}(C_i, C_j) = \\min_{\\mathbf{x} \\in C_i, \\mathbf{x}' \\in C_j} \\|\\mathbf{x} -\\mathbf{x}' \\| $$\n",
    "\n",
    "* Complete linkage\n",
    "$$ d_{max}(C_i, C_j) = \\max_{\\mathbf{x} \\in C_i, \\mathbf{x}' \\in C_j} \\|\\mathbf{x} -\\mathbf{x}' \\| $$\n",
    "\n",
    "* Average linkage\n",
    "$$ d_{avg}(C_i, C_j) = \\frac{1}{n_i n_j}\\sum_{\\mathbf{x} \\in C_i}\\sum_{\\mathbf{x}' \\in C_j} \\|\\mathbf{x} -\\mathbf{x}' \\| $$\n",
    "\n",
    "* Centroid linkage\n",
    "$$ d_{cent}(C_i, C_j) = \\|\\mu_i -\\mu_j \\| $$\n",
    "\n",
    "* Ward linkage\n",
    "$$ d_{ward}(C_i, C_j) = \\sqrt{\\frac{n_i n_j}{n_i + n_j}} \\|\\mu_i - \\mu_j \\|$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формула Ланса-Уильямса (Lance–Williams)\n",
    "\n",
    "$$ d(C_i \\cup C_j, C_k) = a_i \\cdot d(C_i, C_k) + a_j \\cdot d(C_j, C_k) + b \\cdot d(C_i, C_j) + c \\cdot |d(C_i, C_k) - d(C_j, C_k)|$$\n",
    "\n",
    "\n",
    "\n",
    "<center><img src='images/lw_coefs.png' width=400></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "        [1,1],\n",
    "        [2,2],\n",
    "        [2, 2.5],\n",
    "        [5, 2],\n",
    "        [4.5, 5],\n",
    "        [3, 6],\n",
    "        [5, 6],\n",
    "        [6, 6]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# А теперь сделаем это с питоном\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage \n",
    "from scipy.cluster.hierarchy import fcluster, cophenet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Z = linkage(X, method='single', metric='euclidean')\n",
    "dend = dendrogram(Z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##  Эвристика для оценки качества дендрограммы\n",
    "\n",
    "* **Кофенетическое расстояние** между объектами $x_i$ и $x_j$ - высота дерева, при котором эти объекты объединились.\n",
    "\n",
    "\n",
    "<center><img src='images/dendro2.png' width=700></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Кофенетическая корреляция\n",
    "\n",
    "* Кофенетическая корреляция — коэффициент корреляции между массивами попарных расстояний и попарных кофенетических расстояний.\n",
    "\n",
    "$$ \\text{cophCorr} = \\frac{\\sum\\limits_{i < j}(d(x_i, x_j) - \\bar{d})(coph(x_i, x_j) - \\bar{coph})}{\\sqrt{\\sum\\limits_{i < j}(d(x_i, x_j) - \\bar{d})^2 \\cdot \\sum\\limits_{i < j}(coph(x_i, x_j) - \\bar{coph})^2}} $$\n",
    "\n",
    "При \"удачно\" построенном дереве эти ряды должны сильно коррелировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "def coph_demo(link='single', metric='euclidean', k=2):\n",
    "    \n",
    "    X, y = make_blobs(n_samples=500,\n",
    "                  n_features=2,\n",
    "                  centers=4,\n",
    "                  cluster_std=1,\n",
    "                  center_box=(-10.0, 10.0),\n",
    "                  shuffle=True,\n",
    "                  random_state=1) \n",
    "    \n",
    "    d = pdist(X, metric=metric)\n",
    "    \n",
    "    Z = linkage(X, method=link, metric=metric)\n",
    "    labels = fcluster(Z,  k, criterion='maxclust')\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    \n",
    "    ax[0].scatter(X[:,0], X[:,1], c=labels)\n",
    "        \n",
    "    ax[0].set_xlabel('$x_1$')\n",
    "    ax[0].set_ylabel('$x_2$')\n",
    "        \n",
    "    dend = dendrogram(Z, ax=ax[1], truncate_mode='lastp')   \n",
    "    coph_corr, coph_dist = cophenet(Z, d)\n",
    "    \n",
    "    ax[1].set_title('cophCorr = %.3f' % coph_corr)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "interact(coph_demo, k=IntSlider(min=2, max=10, step=1, value=2), link=['complete', 'single', 'average', 'centroid'], metric=['euclidean', 'cityblock'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Итог\n",
    "#### Преимущества\n",
    "*  Несферические кластеры\n",
    "*  Разнообразие критериев\n",
    "*  Любые K из коробки\n",
    "*  Наглядность с дендрограммой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Недостатки\n",
    "*  Требует много ресурсов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Алгоритмы, основанные на плотности\n",
    "<center><img src='images/density.jpg'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Хотелось бы...\n",
    "\n",
    "* Получить кластеры высокой плотности, разделеные участками низкой плотности\n",
    "\n",
    "<center><img src='images/dbscan.png'></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Геоданные\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\"><img src='images/dbscan1.png' width=600></th>\n",
    "    <th class=\"tg-031e\"><img src='images/dbscan2.png' width=600></th>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Основная идея\n",
    "\n",
    "* Для каждой точки кластера её окрестность заданного радиуса $\\epsilon$ должна содержать не менее некоторого числа точек `min_pts`. \n",
    "* C такой точки можно начать расширение \"плотного\" кластера\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Определения и обозначения (Boring)\n",
    "\n",
    "* $N_\\epsilon(x_i)$ — множество точек, расположенных не далее, чем на расстоянии $\\epsilon$ от $x_i$ (плотность).\n",
    "* Точка $p$ **непосредственно плотно-достижима** из точки $q$, если $p\\in N_\\epsilon(q)$ и $| N_\\epsilon (q) | \\geq \\texttt{min_pts}$\n",
    "* Точка $p$ **плотно-достижима** из точки $q$, если существует последовательность точек $p,p_1,p_2,\\dots,p_{n-1},q$ в которой каждая точка непосредственно плотно-достижима из предыдущей\n",
    "* Точка $p$ **плотно-связана** с точкой $q$, если существует точка $o$ , такая что $p$ и $q$ плотно-достижимы из $o$ \n",
    "* **Кластер** – максимальное множество плотно-связанных точек\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Типы объектов\n",
    "* Объект $x_i$ называется **сore-объектом**, если $N_\\epsilon(x_i) \\geq \\texttt{min_pts}$\n",
    "* Объект $x_i$ называется **граничным объектом**, если $N_\\epsilon(x_i) < \\texttt{min_pts}$, но $\\exists x_j : d(x_i, x_j) \\leq \\epsilon$ и $x_j$ - core-объект\n",
    "* Объект $x_i$ называется **шумовым**, если он не является ни граничным ни core объектом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/points.png' width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Алгоритм DBSCAN\n",
    "\n",
    "```{C}\n",
    "1.function dbscan(X, eps, min_pts):\n",
    "2.\tinitialize NV = X # not visited objects\t\n",
    "3.\tfor x in NV:\n",
    "4.\t\tremove(NV, x) # mark as visited\n",
    "5.\t\tnbr = neighbours(x, eps) # set of neighbours\n",
    "6.\t\tif nbr.size < min_pts:\n",
    "7.\t\t\tmark_as_noise(x)\n",
    "8.\t\telse:\n",
    "9.\t\t\tC = new_cluster() \n",
    "10.\t\t\texpand_cluster(x, nbr, C, eps, min_pts, NV)\n",
    "11.\t\t\tyield C\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Метод `expand_cluster`\n",
    "\n",
    "```{C}\n",
    "1. function expand_cluster(x, nbr, C, eps, min_pts, NV):\n",
    "2.\tadd(x, C)\n",
    "3.\tfor x1 in nbr:\n",
    "4.\t\tif x1 in NV: # object not visited\n",
    "5.\t\t\tremove(NV, x1) # mark as visited\n",
    "6.\t\t\tnbr1 = neighbours(x1, eps)\n",
    "7.\t\t\tif nbr1.size >= min_pts:\n",
    "8.\t\t\t\t# join sets of neighbours\n",
    "9.\t\t\t\tmerge(nbr, nbr_1) \n",
    "10.\t\tif x1 not in any cluster:\n",
    "11.\t\t\tadd(x1, C)\t\t\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Demo\n",
    "\n",
    "[Тык](https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "data = np.loadtxt('./data/flame.txt')\n",
    "X_data = data[:, :2]\n",
    "\n",
    "def dbscan_demo(eps=1, min_pts=5):\n",
    "    \n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_pts).fit(X_data)\n",
    "    \n",
    "    labels = dbscan.labels_\n",
    "    \n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.scatter(X_data[:,0], X_data[:, 1], c=labels)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "interact(dbscan_demo, eps=FloatSlider(min=0.1, max=10, step=0.05, value=1), min_pts=IntSlider(min=2, max=15, step=1, value=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Итог\n",
    "\n",
    "#### Преимущества\n",
    "* Не требует $K$\n",
    "* Кластеры произвольной формы\n",
    "* Учитывает выбросы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Недостатки\n",
    "* Не работает при различных плотностях кластеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/dbprob.png' width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Что еще?\n",
    "\n",
    "* Моделирование смеси распределений - Mixture Models (будет дальше)\n",
    "* Спектральная кластеризация\n",
    "* Выявление сообществ на сети (Community Detection)\n",
    "\n",
    "<center><img src='https://cdn-images-1.medium.com/max/1600/1*fVGpU47jjKRVKdiYqeODkw.png' width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Литература\n",
    "* [Mohammed J. Zaki, Ch3](https://www.amazon.com/Data-Mining-Analysis-Fundamental-Algorithms/dp/0521766338)\n",
    "* [Jure Leskovec, Anand Rajaraman, Jeffrey D. Ullman, Ch7](http://www.mmds.org/)\n",
    "* [Andrew R. Webb, Keith D. Copsey, Ch11](http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470682272.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Вопросы?\n",
    "\n",
    "### Пожалуйста, напишите отзыв о лекции"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "livereveal": {
   "theme": "serif",
   "transition": "concave",
   "width": "1024px"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "513px",
    "width": "253px"
   },
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc_position": {
   "height": "32px",
   "left": "9px",
   "right": "1379px",
   "top": "33px",
   "width": "212px"
  },
  "widgets": {
   "state": {
    "54e80d57f79b4bfc934a2b84cf5fe7ba": {
     "views": [
      {
       "cell_index": 47
      }
     ]
    },
    "5fb17a3592634a4fba98446dacd6db43": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "6f6f6ce7b81743308b92966f225862a8": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
