{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/header.png\"></center>\n",
    "\n",
    "<h1><center>Алгоритмы интеллектуальной обработки больших объемов данных</center></h1>\n",
    "<hr>\n",
    "<h2><center>Меры качества кластеризации, уменьшение размерности признаков</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "try:\n",
    "    from ipywidgets import interact, IntSlider, fixed, FloatSlider\n",
    "except ImportError:\n",
    "    print u'Так надо'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Методы уменьшения размерности признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/curse.png' width=800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Проклятье размености\n",
    "\n",
    "<center><img src='images/curse_2.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Проклятье размерности\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">$d=2$<img src='https://jeremykun.files.wordpress.com/2016/01/2d-distances.png' width=400></th>\n",
    "    <th class=\"tg-031e\">$d=2 \\dots 100$<img src='https://jeremykun.files.wordpress.com/2016/01/distances-animation.gif' width=400></th>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "$$ \\lim_{d \\rightarrow \\infty} \\frac{\\text{dist}_{max} - \\text{dist}_{min}}{\\text{dist}_{min}} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Способы понижения размерности\n",
    "\n",
    "Избавляться от размерности можно методами **отбора признаков (Feature Selection)** и методами **уменьшения размерности (Feature Reduction)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Feature Selection \n",
    "Методы деляться на следующие группы:\n",
    "* Unsupervised methods\n",
    "    * Определяем полезность признака вне зависимости от целевой переменной\n",
    "* Filter methods \n",
    "    * Признаки рассматриваются независимо друг от друга\n",
    "    * Изучается индивидуальный \"вклад\" призника в предсказываемую переменную\n",
    "    * Быстрое вычисление\n",
    "    * *Пример?*\n",
    "* Wrapper methods\n",
    "    * Идет отбор группы признаков\n",
    "    * Может быть оооочень медленным, но качество, обычно, лучше чем у Filter Methods\n",
    "    * Примеры: Stepwise feature selection for regression, [Boruta Algorithm](https://www.google.ru/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&ved=0ahUKEwif5biy-fTWAhXkYJoKHbdxCLAQFgg2MAE&url=https%3A%2F%2Fwww.jstatsoft.org%2Farticle%2Fview%2Fv036i11%2Fv36i11.pdf&usg=AOvVaw3tyiHN0BCe2fkkAA6xEVDE)\n",
    "* Embedded methods\n",
    "    * Отбор признаков \"зашит\" в модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Filter method - Mutual Information\n",
    "$$MI(y,x) = \\sum_{x,y} p(x,y) \\ln\\left[\\frac{p(x,y)}{p(x)p(y)}\\right]$$\n",
    "Сколько информации $x$ сообщает об $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic = pd.read_csv('titanic.csv')\n",
    "df_titanic.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058107252690322631"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "pd.crosstab(df_titanic.Survived, df_titanic.Sex, normalize=True)\n",
    " \n",
    "mutual_info_score(df_titanic.Survived.values,\n",
    "                  df_titanic.Pclass.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Wrapper Methods - Recursive Feature Elimination\n",
    "\n",
    "При данном подходе из линейной модели последовательно удаляются признаки с наименьшим коэффициентом\n",
    "\n",
    "Выбор итоговой модели можно производить по одному из следующих критериев, оценивающих сложность и точность модели:\n",
    "* [AIC](https://ru.wikipedia.org/wiki/%D0%98%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D1%8B%D0%B9_%D0%BA%D1%80%D0%B8%D1%82%D0%B5%D1%80%D0%B8%D0%B9_%D0%90%D0%BA%D0%B0%D0%B8%D0%BA%D0%B5)\n",
    "* [BIC](https://en.wikipedia.org/wiki/Bayesian_information_criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Principal Component Analysis\n",
    "## Метод Главных Компонент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Интерпретация\n",
    "\n",
    "* Интерпретация 1: находит такие ортогональные направления, вдоль которых дисперсия данных максимальна\n",
    "\n",
    "<center><img src='http://www.visiondummy.com/wp-content/uploads/2014/05/correlated_2d.png' width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Интерпретация\n",
    "\n",
    "* Интерпретация 2: Найти такое подпространство меньшей размерности $L$ Такое что различие между точками и их проекциями минимальна\n",
    "\n",
    "<center><img src='images/pca_example.png' width=800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Определение PCA\n",
    "\n",
    "Рассмотрим точку $x$ и пространство $L$: \n",
    "\n",
    "* $p$: проекция $x$ на $L$ \n",
    "* $h$: ортогональное дополнение\n",
    "* $x=p+h$, $\\langle p,h\\rangle=0$, \n",
    "\n",
    "#### Предложение:\n",
    "$\\|x\\|^2 = \\|p\\|^2 + \\|h\\|^2$\n",
    "\n",
    "Если у нас есть обучающая выборка $x_{1},x_{2},...x_{N}$ и подпространоство $L$  то можно легко найти:\n",
    "\n",
    "* проекции: $p_{1},p_{2},...p_{N}$\n",
    "* дополнения: $h_{1},h_{2},...h_{N}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Определение PCA\n",
    "#### Определение\n",
    "Наилучшим $k$-мерным подпространством для точек $x_1 \\dots x_N$ назовем подпространство, натянутое на $k$ векторов $v_1$, $v_2$, $\\dots$, $v_k$, при котором\n",
    "\n",
    "$$ \\sum_{n=1}^N \\| h_n \\| ^2 \\rightarrow \\min\\limits_{v_1, v_2,\\dots,v_k}$$\n",
    "\n",
    "или\n",
    "\n",
    "$$ \\sum_{n=1}^N \\| p_n \\| ^2 \\rightarrow \\max\\limits_{v_1, v_2,\\dots,v_k}$$\n",
    "\n",
    "#### Определение PCA\n",
    "Главные компоненты $a_1, a_2, \\dots, a_k$ - это вектора, формирующие ортонормированный базис для наилучшего $k$-мерного подпространства"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Пример\n",
    "\n",
    "\n",
    "<center><img src='images/plane_best_fit.png' width=500></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## EigenFaces\n",
    "\n",
    "<center><img src='images/faces.png' width=500></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## EigenFaces\n",
    "\n",
    "<center><img src='images/eigenfaces.png' width=500></center>\n",
    "<center><img src='images/eigenfaces2.png' width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Построение PCA\n",
    "\n",
    "* Данные $X$ отцентрированы и отшкалированы\n",
    "* Главные компоненты $a_{1},a_{2},...a_{D}\\in\\mathbb{R}^{D}$ обладают свойством, что $\\langle a_{i},a_{j}\\rangle=\\begin{cases}\n",
    "1, & i=j\\\\\n",
    "0 & i\\ne j\n",
    "\\end{cases}$\n",
    "* $Xa_{i}$ - процекция всех точек на  $i$-ую главную компоненту\n",
    "* Координаты проекции точки $x$ на оси главных компонен вычисляются как:\n",
    "$$\n",
    "p=A^{T}x=[\\langle a_{1},x\\rangle,...\\langle a_{D},x\\rangle]^{T}\n",
    "$$\n",
    "где $A=[a_{1};a_{2};...a_{D}]\\in\\mathbb{R}^{DxD}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Построение PCA\n",
    "\n",
    "Последовательное построение\n",
    "\n",
    "1. $a_{1}$ должна максимизировать $\\left\\lVert Xa_{1}\\right\\rVert^2 $\n",
    "при условии $\\langle a_{1},a_{1}\\rangle=1$\n",
    "2. $a_{2}$ должна максимизировать $\\left\\lVert Xa_{2}\\right\\rVert^2 $\n",
    "при условии $\\langle a_{2},a_{2}\\rangle=1$, $\\langle a_{2},a_{1}\\rangle=0$\n",
    "3. $a_{3}$ должна максимизировать $\\left\\lVert Xa_{3}\\right\\rVert^2 $\n",
    "при условии $\\langle a_{3},a_{3}\\rangle=1$, $\\langle a_{3},a_{1}\\rangle=\\langle a_{3},a_{2}\\rangle=0$\n",
    "\n",
    "\n",
    "и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Первая компонента\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "\\|X a_1 \\|^2 \\rightarrow \\max_{a_1} \\\\\n",
    "a_1^\\top a_1 = 1\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "* Строим лагранжиан\n",
    "$$ \\mathcal{L}(a_1, \\nu) = a_1^\\top X^\\top X a_1 - \\nu (a_1^\\top a_1 - 1) \\rightarrow max_{a_1, \\nu}$$\n",
    "* Считем производную по $a_1$\n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial a_1} = 2X^\\top X a_1 - 2\\nu a_1 = 0 $$\n",
    "* значит $a_1$ выбирается из собственных векторов матрицы  $X^\\top X$. Но как выбрать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Полезные свойства $X^\\top X$\n",
    "\n",
    "* $X^\\top X$ - симметричная и положительно-определенная матрица\n",
    "    * $(X^\\top X)\\top = X^\\top X$\n",
    "    * $\\forall a \\in \\mathbb{R}^D:\\ a^\\top (X^\\top X) a = \\|Xa\\|^2 \\geq 0$\n",
    "* Свойства\n",
    "    * Все собственные числа $\\lambda_i \\in \\mathbb{R}, \\lambda_i \\geq 0$ (упорядочим индексы по возрастанию так, что $\\lambda_1 \\geq \\lambda_2  \\geq \\dots \\geq \\lambda_d $)\n",
    "    * Собственные вектора при $\\lambda_i \\neq \\lambda_j $ ортогональны: $v_i^\\top v_j = 0$\n",
    "    * Для уникальных $\\lambda_i$ уникальны и $v_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Снова первая компонента\n",
    "\n",
    "Изначально было так \n",
    "$$\\|X a_1 \\|^2 = a_1^\\top X^\\top X a_1  \\rightarrow \\max_{a_1}$$\n",
    "\n",
    "Из лагранжиана мы поняли, что\n",
    "$$X^\\top X a_1 = \\nu a_1$$\n",
    "\n",
    "Подставим одно в другое:\n",
    "$$ a_1^\\top X^\\top X a_1 = \\nu a_1^\\top a_1 = \\nu \\rightarrow \\max$$\n",
    "\n",
    "Что значит, что:\n",
    "* $\\nu$ - наибольшее собственное число матрицы $X^\\top X$, а именно - $\\lambda_1$\n",
    "* $a_1$ - собственный вектор при $\\lambda_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Вторая компонента\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "\\|X a_2 \\|^2 \\rightarrow \\max_{a_2} \\\\\n",
    "a_2^\\top a_2 = 1 \\\\\n",
    "a_2^\\top a_1 = 0\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "* Лагранжиан\n",
    "$$ \\mathcal{L}(a_2, \\nu,\\alpha) = a_2^\\top X^\\top X a_2 - \\nu (a_2^\\top a_2 - 1) - \\alpha (a_1^\\top a_2) \\rightarrow max_{a_2, \\nu,\\alpha}$$\n",
    "* Производная по $a_2$\n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial a_2} = 2X^\\top X a_2 - 2\\nu a_2 - \\alpha a_1 = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Вторая компонента\n",
    "* Домножим на $a_1^\\top$ :\n",
    "$$ a_1^\\top\\frac{\\partial\\mathcal{L}}{\\partial a_2} = 2a_1^\\top X^\\top X a_2 - 2\\nu a_1^\\top a_2 - \\alpha a_1^\\top a_1 = 0 $$\n",
    "\n",
    "* Отсюда $\\alpha a_1^\\top a_1 = \\alpha = 0$\n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial a_2} = 2X^\\top X a_2 - \\nu a_2 = 0 $$\n",
    "Значит $a_2$ - собственный вектор при втором по величине собственном числе матрицы $X^\\top X$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Сколько компонент брать\n",
    "\n",
    "* Величина\n",
    "$$\n",
    "\\frac{\\lambda_{i}}{\\sum_{d=1}^{D}\\lambda_{d}}\n",
    "$$\n",
    "Показывает долю объясненной дисперии компонентой $i$\n",
    "\n",
    "<center><img src='images/cumul_rat.png' width=900></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Резюме\n",
    "\n",
    "* PCA понижает размерность признакового пространства\n",
    "* Новые компоненты являются линейной комбинацией исходных признаков\n",
    "* Новые компоненты - ортогональны\n",
    "* Можно применять в моделях и для визуализации\n",
    "* [PCA SVD туториал](https://www.cs.princeton.edu/picasso/mats/PCA-Tutorial-Intuition_jp.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# t-SNE\n",
    "## t-distributed stochastic neighbor embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Идея\n",
    "\n",
    "* Перейти в пространство меньшей размерности так, чтобы расстояния между объектами в новом пространстве были подобны расстояниям в исходном пространстве.\n",
    "* Это многомерное шкалирование!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/mds.png' width =1200></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* t-SNE - почти про это, но вместо этого мы будем пытаться перенести окрестность точек из исходного пространства в пространоство меньшей размерности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Схожесть между объектами в исходном пространстве $\\mathbb{R}^m$\n",
    "$$\n",
    "p(i, j) = \\frac{p(i | j) + p(j | i)}{2n}, \\quad p(j | i) = \\frac{\\exp(-\\|\\mathbf{x}_j-\\mathbf{x}_i\\|^2/{2 \\sigma_i^2})}{\\sum_{k \\neq i}\\exp(-\\|\\mathbf{x}_k-\\mathbf{x}_i\\|^2/{2 \\sigma_i^2})}\n",
    "$$\n",
    "$\\sigma_i$ неявно задается пользователем\n",
    "* Схожесть между объектами в целевом пространстве $\\mathbb{R}^k, k << m$\n",
    "$$\n",
    "q(i, j) = \\frac{g(|\\mathbf{y}_i - \\mathbf{y}_j|)}{\\sum_{k \\neq l} g(|\\mathbf{y}_i - \\mathbf{y}_j|)}\n",
    "$$ \n",
    "где $g(z) = \\frac{1}{1 + z^2}$ - распределение Коши (t-распределение Стьюдента с 1 степенью свободы)\n",
    "* Критерий\n",
    "$$\n",
    "J_{t-SNE}(y) = KL(P \\| Q) = \\sum_i \\sum_j p(i, j) \\log \\frac{p(i, j)}{q(i, j)} \\rightarrow \\min\\limits_{\\mathbf{y}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Дивергенция Кульбака-Лейблера\n",
    "\n",
    "* Насколько распределение $P$ отличается от распределения $Q$?\n",
    "$$\n",
    "KL(P \\| Q) = \\sum_z P(z) \\log \\frac{P(z)}{Q(z)}\n",
    "$$\n",
    "\n",
    "<center><img src='images/kld.png' width=1200></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Оптимизация\n",
    "\n",
    "* Оптимизируем $J_{t-SNE}(y)$ с помощью градиентного спуска\n",
    "\n",
    "$$\\frac{\\partial J_{t-SNE}}{\\partial y_i}=4 \\sum_j(p(i,j)−q(i,j))(y_i−y_j)g(|y_i−y_j|)$$\n",
    "\n",
    "* [Статья](http://jmlr.csail.mit.edu/papers/volume9/vandermaaten08a/vandermaaten08a.pdf)\n",
    "* [Примеры](http://lvdmaaten.github.io/tsne/)\n",
    "* [Демо и советы](http://distill.pub/2016/misread-tsne/)\n",
    "    * t-SNE может быть нестабильным\n",
    "    * Размеры полученных сгустков могут ничего не значить\n",
    "    * Расстояния между кластерами могут ничего не значить\n",
    "    * Полностью шумовые данные могут выдать структуру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='http://lvdmaaten.github.io/tsne/examples/mnist_tsne.jpg' width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/mainfold.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Вопросы?\n",
    "\n",
    "## Пожалуйста, оставьте отзыв о лекции"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "livereveal": {
   "theme": "serif",
   "transition": "concave",
   "width": "1024px"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "513px",
    "width": "253px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "toc_position": {
   "height": "973px",
   "left": "0px",
   "right": "1708px",
   "top": "109px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
